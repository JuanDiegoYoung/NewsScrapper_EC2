# NewsScrapperEC2

Sistema de scraping y anÃ¡lisis de noticias financieras optimizado para deployment directo en EC2 (sin Docker).

## ğŸ¯ CaracterÃ­sticas

- **Scraping automÃ¡tico** de noticias financieras desde mÃºltiples fuentes RSS
- **Resumen con OpenAI** para anÃ¡lisis conciso de artÃ­culos
- **Almacenamiento en S3** para histÃ³rico y anÃ¡lisis
- **API FastAPI** para acceso programÃ¡tico a los datos
- **Servicio systemd** para ejecuciÃ³n automatizada cada 6 horas
- **Logs estructurados** en formato JSON para CloudWatch
- **Deployment simplificado** con scripts automatizados

## ğŸ“ Estructura del Proyecto

```
NewsScrapperEC2/
â”œâ”€â”€ src/                      # CÃ³digo fuente
â”‚   â”œâ”€â”€ scraper/              # LÃ³gica de scraping
â”‚   â”‚   â”œâ”€â”€ scrape_and_summarize.py
â”‚   â”‚   â””â”€â”€ save_bucket.py
â”‚   â””â”€â”€ api/                  # API FastAPI
â”‚       â””â”€â”€ api.py
â”œâ”€â”€ config/                   # ConfiguraciÃ³n
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ logger_utils.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ data/                     # Datos locales (opcional)
â”œâ”€â”€ logs/                     # Logs del scraper y API
â”œâ”€â”€ deploy_ec2.sh             # Script de deployment
â”œâ”€â”€ setup_ec2.sh              # Setup inicial en EC2
â”œâ”€â”€ setup_systemd.sh          # Configurar servicios
â”œâ”€â”€ start_scraper.sh          # Ejecutar manualmente
â”œâ”€â”€ stop_scraper.sh           # Detener servicios
â”œâ”€â”€ monitor.sh                # Monitorear estado
â””â”€â”€ quick_update.sh           # ActualizaciÃ³n rÃ¡pida
```

## ğŸš€ Quick Start

### 1. Deployment a EC2

Desde tu mÃ¡quina local:

```bash
# Hacer ejecutables los scripts
chmod +x *.sh

# Deployar a EC2
./deploy_ec2.sh ubuntu ec2-xx-xxx-xxx-xxx.compute-1.amazonaws.com
```

### 2. Setup en EC2

ConÃ©ctate al servidor:

```bash
ssh -i "tu-clave.pem" ubuntu@ec2-xx-xxx-xxx-xxx.compute-1.amazonaws.com
cd ~/NewsScrapperEC2
```

Ejecuta el setup:

```bash
./setup_ec2.sh
```

### 3. Configurar Credenciales

Edita el archivo `.env`:

```bash
nano .env
```

Completa las variables:

```bash
# AWS Configuration
AWS_ACCESS_KEY_ID=AKIAXXXXXXXXXXXXXXXX
AWS_SECRET_ACCESS_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
AWS_REGION=us-east-1
BUCKET=jd-finance-news
PREFIX=runs/

# OpenAI Configuration
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Email (opcional)
EMAIL_SENDER=your_email@example.com
EMAIL_PASSWORD=your_app_password
EMAIL_RECIPIENTS=recipient@example.com

# Scraper Configuration
SCRAPER_INTERVAL_HOURS=6
MAX_ARTICLES_PER_RUN=50
```

TambiÃ©n configura AWS CLI:

```bash
aws configure
```

### 4. Probar Manualmente

```bash
./start_scraper.sh
```

### 5. Configurar Servicio AutomÃ¡tico

```bash
./setup_systemd.sh
sudo systemctl start newscrapper-ec2.timer
```

## ğŸ“Š Monitoreo

### Ver Estado

```bash
# Ejecutar script de monitoreo
./monitor.sh

# Ver estado de servicios
sudo systemctl status newscrapper-ec2.timer
sudo systemctl status newscrapper-ec2-api
```

### Ver Logs

```bash
# Logs en tiempo real
sudo journalctl -u newscrapper-ec2 -f

# Logs archivados
tail -f logs/scraper.log
tail -f logs/scraper_error.log
```

## ğŸ”„ Actualizar CÃ³digo

### ActualizaciÃ³n Completa

```bash
# Desde tu mÃ¡quina local
./deploy_ec2.sh ubuntu ec2-host.amazonaws.com
```

### ActualizaciÃ³n RÃ¡pida (solo cÃ³digo Python)

```bash
# Desde tu mÃ¡quina local
./quick_update.sh ubuntu ec2-host.amazonaws.com
```

## ğŸŒ API

### Habilitar API

```bash
sudo systemctl enable newscrapper-ec2-api
sudo systemctl start newscrapper-ec2-api
```

### Endpoints Disponibles

```bash
# Health check
GET /health

# Resumen mÃ¡s reciente
GET /resumen/latest
Header: X-API-Key: tu-api-key

# Resumen de fecha especÃ­fica
GET /resumen/2025-12-09
Header: X-API-Key: tu-api-key

# HistÃ³rico completo
GET /historico
Header: X-API-Key: tu-api-key

# Listar feeds RSS
GET /rss/list
Header: X-API-Key: tu-api-key

# Forzar scraping
POST /scrape/run
Header: X-API-Key: tu-api-key
```

## âš™ï¸ ConfiguraciÃ³n Avanzada

### Cambiar Frecuencia de Scraping

```bash
sudo nano /etc/systemd/system/newscrapper-ec2.timer
```

Cambia `OnUnitActiveSec=6h` a:
- `1h` = cada hora
- `3h` = cada 3 horas
- `12h` = cada 12 horas
- `1d` = diario

Luego:

```bash
sudo systemctl daemon-reload
sudo systemctl restart newscrapper-ec2.timer
```

### Configurar Nginx como Reverse Proxy

```bash
sudo apt-get install -y nginx

sudo nano /etc/nginx/sites-available/newscrapper
```

Agregar:

```nginx
server {
    listen 80;
    server_name tu-dominio.com;

    location / {
        proxy_pass http://localhost:8000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }
}
```

Activar:

```bash
sudo ln -s /etc/nginx/sites-available/newscrapper /etc/nginx/sites-enabled/
sudo nginx -t
sudo systemctl restart nginx
```

## ğŸ”’ Seguridad

### Usar IAM Role (Recomendado)

En lugar de usar Access Keys en `.env`:

1. Crea un IAM Role con permisos para S3, Secrets Manager y CloudWatch
2. Asigna el role a la instancia EC2
3. Elimina `AWS_ACCESS_KEY_ID` y `AWS_SECRET_ACCESS_KEY` del `.env`

### Security Group

AsegÃºrate de que tu Security Group permite:
- SSH (22) desde tu IP
- HTTP (80) si usas Nginx
- Puerto 8000 si accedes directamente a la API

## ğŸ†˜ Troubleshooting

### El scraper no se ejecuta

```bash
# Ver errores
sudo journalctl -u newscrapper-ec2 -n 50

# Probar manualmente
cd ~/NewsScrapperEC2
source venv/bin/activate
python src/scraper/scrape_and_summarize.py
```

### Error de credenciales AWS

```bash
# Verificar configuraciÃ³n
aws sts get-caller-identity

# Verificar variables
cat .env | grep AWS
```

### Logs no se generan

```bash
# Verificar permisos
ls -la ~/NewsScrapperEC2/logs/

# Crear si no existe
mkdir -p ~/NewsScrapperEC2/logs
chmod 755 ~/NewsScrapperEC2/logs
```

## ğŸ“ Comandos de Referencia RÃ¡pida

```bash
# Deployment
./deploy_ec2.sh ubuntu ec2-host.amazonaws.com

# Setup inicial (una vez)
./setup_ec2.sh
./setup_systemd.sh

# Control de servicios
sudo systemctl start newscrapper-ec2.timer
sudo systemctl stop newscrapper-ec2.timer
sudo systemctl restart newscrapper-ec2.timer
sudo systemctl status newscrapper-ec2.timer

# EjecuciÃ³n manual
./start_scraper.sh

# Monitoreo
./monitor.sh
sudo journalctl -u newscrapper-ec2 -f

# ActualizaciÃ³n
./quick_update.sh ubuntu ec2-host.amazonaws.com
```

## ğŸ“ˆ Diferencias con la VersiÃ³n Docker

Esta versiÃ³n estÃ¡ optimizada para EC2:

- âœ… **No requiere Docker** - deployment mÃ¡s simple
- âœ… **Systemd nativo** - integraciÃ³n con el sistema operativo
- âœ… **Mejor performance** - sin overhead de containers
- âœ… **Logs directos** - mÃ¡s fÃ¡cil debugging
- âœ… **Updates mÃ¡s rÃ¡pidos** - sin rebuild de imÃ¡genes
- âœ… **Menor uso de recursos** - ideal para instancias pequeÃ±as

## ğŸ“š Recursos

- [AWS EC2 Documentation](https://docs.aws.amazon.com/ec2/)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Systemd Documentation](https://www.freedesktop.org/software/systemd/man/systemd.service.html)
- [OpenAI API](https://platform.openai.com/docs/api-reference)

## ğŸ“ Notas

- El scraper se ejecuta cada 6 horas por defecto
- Los resultados se guardan en S3 con particionado por fecha
- Los logs se rotan automÃ¡ticamente por systemd
- La API requiere autenticaciÃ³n via X-API-Key header

---

**VersiÃ³n**: 2.0  
**Ãšltima actualizaciÃ³n**: Diciembre 2025  
**Autor**: Juan Diego Young
